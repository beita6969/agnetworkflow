# A100服务器部署指南
# A100 Server Deployment Guide

## ✅ 服务器信息

### 连接信息
```
地址: ssh root@0.tcp.ngrok.io -p 11729
密码: MLUerV93OMJH
```

### 硬件配置
```
GPU: NVIDIA A100-SXM4-40GB
显存: 40GB
驱动: 550.54.15
CUDA: 12.4
存储: 197GB 可用
```

### GPU状态
```
✅ nvidia-smi: 正常工作（需要设置LD_LIBRARY_PATH）
✅ CUDA available: True
✅ GPU温度: 33°C
✅ GPU利用率: 0% (空闲)
```

---

## ✅ 已完成的工作

### 1. 文件已上传
所有训练文件已上传到 `/root/aflow_training/`：

```
deep_config_full_scale.yaml       (2.9KB)  - 训练配置
deep_train_real_workflow.py        (16KB)  - 主训练脚本
deep_workflow_env.py                (15KB)  - RL环境
evaluate_full_dataset.py           (8.8KB)  - 评估脚本
rl_trainer.py                       (20KB)  - RL训练器
start_full_scale_training.sh       (4.6KB)  - 启动脚本
trainable_qwen_policy.py            (12KB)  - Qwen策略
unified_state.py                    (17KB)  - 统一状态
workflow_evaluator.py               (12KB)  - Workflow评估器
workflow_parser.py                  (12KB)  - Workflow解析器
workflow_prompt_manager.py         (7.5KB)  - Prompt管理
```

### 2. 环境检查
```
✅ Python 3
✅ PyTorch 2.8.0+cu126
✅ transformers (已安装)
✅ peft (已安装)
✅ datasets (已安装)
✅ CUDA available: True
```

---

## ⚠️ 还需要完成的步骤

### 第1步：修复环境变量

GPU库路径需要在每次使用时设置。创建环境配置：

```bash
ssh root@0.tcp.ngrok.io -p 11729
# 密码: MLUerV93OMJH

# 添加到 .bashrc
echo 'export LD_LIBRARY_PATH=/usr/lib64-nvidia:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# 验证
nvidia-smi
```

### 第2步：下载Qwen模型（~15GB，需要20-30分钟）

```bash
# 创建模型目录
mkdir -p /root/models

# 安装huggingface-hub（如果没有）
pip install huggingface-hub

# 下载Qwen2.5-7B-Instruct模型
cd /root/models
python3 -c "
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id='Qwen/Qwen2.5-7B-Instruct',
    local_dir='/root/models/Qwen2.5-7B-Instruct',
    local_dir_use_symlinks=False,
    resume_download=True
)
"

# 验证模型已下载
ls -lh /root/models/Qwen2.5-7B-Instruct/
# 应该看到 model-*.safetensors 文件（约15GB）
```

### 第3步：安装/克隆AFlow框架

这个服务器似乎没有AFlow。有两个选项：

#### 选项A：从GitHub克隆
```bash
cd /root
git clone https://github.com/geekan/AFlow.git
cd AFlow
pip install -e .
```

#### 选项B：如果已有AFlow代码
如果您在其他地方（如原来的服务器）已经有AFlow代码，可以打包后上传。

### 第4步：配置API密钥

```bash
cd /root/aflow_training

# 编辑配置文件
vim deep_config_full_scale.yaml

# 修改以下行（第32和39行）：
# 将 "YOUR_OPENAI_API_KEY_HERE"
# 改为您的真实API密钥 "sk-..."
```

### 第5步：安装其他依赖包（如果需要）

```bash
# 可能需要的包
pip install pyyaml
pip install openai
pip install anthropic  # 如果使用Claude
pip install human-eval  # 用于HumanEval评估
```

---

## 🚀 启动训练

完成上述所有步骤后：

```bash
cd /root/aflow_training

# 确保环境变量已设置
export LD_LIBRARY_PATH=/usr/lib64-nvidia:$LD_LIBRARY_PATH

# 启动训练
chmod +x start_full_scale_training.sh
./start_full_scale_training.sh

# 或者直接运行
nohup python3 deep_train_real_workflow.py \
  --config deep_config_full_scale.yaml \
  > full_scale_training.log 2>&1 &

# 监控训练
tail -f full_scale_training.log

# 查看准确率
grep "Pass@" full_scale_training.log | tail -20
```

---

## 📊 训练配置详情

### 当前配置
```yaml
device: "cuda"
total_epochs: 30
episodes_per_epoch: 5
sample: 131  # 完整训练集
experience_pool_size: 20000
model_path: "/root/models/Qwen2.5-7B-Instruct"
```

### 预计训练时间
```
每episode: ~70分钟（131个问题）
每epoch: ~5.8小时（5个episodes）
总耗时: ~174小时（~7.25天，30个epochs）
```

### A100性能优势
在A100上训练会比普通GPU快很多：
- A100 vs RTX 3090: 约 **1.5-2x** 速度提升
- 预计总耗时可能缩短到 **4-5天**

---

## 🔧 故障排查

### 问题1：nvidia-smi报错
```bash
# 设置环境变量
export LD_LIBRARY_PATH=/usr/lib64-nvidia:$LD_LIBRARY_PATH
nvidia-smi
```

### 问题2：CUDA不可用
```bash
# 验证PyTorch CUDA
python3 -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'GPU name: {torch.cuda.get_device_name(0)}')
"

# 如果False，重装PyTorch
pip uninstall torch
pip install torch --index-url https://download.pytorch.org/whl/cu124
```

### 问题3：找不到Qwen模型
```bash
# 检查模型路径
ls -la /root/models/Qwen2.5-7B-Instruct/

# 如果没有，重新下载（见第2步）
```

### 问题4：找不到AFlow模块
```bash
# 检查AFlow安装
python3 -c "import aflow; print('✅ AFlow已安装')"

# 如果报错，安装AFlow（见第3步）
```

### 问题5：OpenAI API错误
```bash
# 检查API密钥配置
grep "key:" deep_config_full_scale.yaml

# 确保是真实密钥，以 sk- 开头
vim deep_config_full_scale.yaml
```

---

## 📝 快速检查清单

在启动训练前，逐项确认：

```
[ ] 1. 环境变量已设置（LD_LIBRARY_PATH）
[ ] 2. nvidia-smi 正常工作
[ ] 3. CUDA available: True
[ ] 4. Qwen模型已下载（/root/models/Qwen2.5-7B-Instruct/）
[ ] 5. AFlow已安装
[ ] 6. OpenAI API密钥已配置
[ ] 7. 依赖包已安装（pyyaml, openai等）
[ ] 8. 所有训练文件在 /root/aflow_training/
```

---

## 🎯 一键部署脚本（可选）

创建一个一键部署脚本来自动完成上述步骤：

```bash
#!/bin/bash
# /root/aflow_training/setup_and_train.sh

set -e  # Exit on error

echo "=== 开始A100服务器部署 ==="
echo ""

# 1. 环境变量
echo "[1/6] 配置环境变量..."
export LD_LIBRARY_PATH=/usr/lib64-nvidia:$LD_LIBRARY_PATH
echo 'export LD_LIBRARY_PATH=/usr/lib64-nvidia:$LD_LIBRARY_PATH' >> ~/.bashrc
nvidia-smi
echo ""

# 2. 下载Qwen模型
if [ ! -d "/root/models/Qwen2.5-7B-Instruct" ]; then
    echo "[2/6] 下载Qwen模型（~15GB，需要20-30分钟）..."
    mkdir -p /root/models
    cd /root/models
    python3 -c "
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id='Qwen/Qwen2.5-7B-Instruct',
    local_dir='/root/models/Qwen2.5-7B-Instruct',
    local_dir_use_symlinks=False,
    resume_download=True
)
"
    echo "✅ Qwen模型下载完成"
else
    echo "[2/6] Qwen模型已存在，跳过下载"
fi
echo ""

# 3. 安装AFlow
if ! python3 -c "import aflow" 2>/dev/null; then
    echo "[3/6] 安装AFlow..."
    cd /root
    if [ ! -d "AFlow" ]; then
        git clone https://github.com/geekan/AFlow.git
    fi
    cd AFlow
    pip install -e .
    echo "✅ AFlow安装完成"
else
    echo "[3/6] AFlow已安装，跳过"
fi
echo ""

# 4. 安装依赖
echo "[4/6] 安装依赖包..."
pip install -q pyyaml openai human-eval anthropic
echo "✅ 依赖包安装完成"
echo ""

# 5. 验证环境
echo "[5/6] 验证环境..."
python3 << 'EOF'
import torch
print(f"✅ CUDA available: {torch.cuda.is_available()}")
print(f"✅ GPU: {torch.cuda.get_device_name(0)}")

import os
model_path = "/root/models/Qwen2.5-7B-Instruct"
if os.path.exists(model_path):
    print(f"✅ Qwen model exists")
else:
    print(f"❌ Qwen model NOT found at {model_path}")
    exit(1)

try:
    import aflow
    print("✅ AFlow imported")
except:
    print("❌ AFlow NOT found")
    exit(1)
EOF
echo ""

# 6. 提示配置API密钥
echo "[6/6] 请配置OpenAI API密钥..."
echo "运行: vim /root/aflow_training/deep_config_full_scale.yaml"
echo "修改 key: 'YOUR_OPENAI_API_KEY_HERE' 为您的真实API密钥"
echo ""

echo "=== 部署完成！==="
echo ""
echo "下一步:"
echo "1. 配置API密钥: vim /root/aflow_training/deep_config_full_scale.yaml"
echo "2. 启动训练: cd /root/aflow_training && ./start_full_scale_training.sh"
echo ""
```

保存并运行：
```bash
chmod +x /root/aflow_training/setup_and_train.sh
/root/aflow_training/setup_and_train.sh
```

---

## 📞 服务器信息摘要

```
连接: ssh root@0.tcp.ngrok.io -p 11729
密码: MLUerV93OMJH
GPU: NVIDIA A100-SXM4-40GB (40GB)
工作目录: /root/aflow_training/
配置文件: deep_config_full_scale.yaml
```

---

## ✅ 当前状态

### 已完成
- ✅ 找到A100 GPU服务器
- ✅ 验证GPU可用（CUDA: True）
- ✅ 上传所有训练文件
- ✅ 基础Python包已安装

### 待完成
- ⏳ 配置环境变量（LD_LIBRARY_PATH）
- ⏳ 下载Qwen模型（~15GB）
- ⏳ 安装AFlow框架
- ⏳ 配置OpenAI API密钥
- ⏳ 启动训练

---

**📝 文档生成时间**: 2025-10-15 14:10
**📍 工作目录**: `/root/aflow_training/`
**🎯 目标**: 在A100上进行完整HumanEval数据集训练（131个问题）
**⏱️ 预计耗时**: 4-5天（A100加速后）
