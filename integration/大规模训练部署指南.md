# 大规模训练部署指南
# Large-Scale Training Deployment Guide

## 📋 概览

本指南说明如何在GPU服务器上部署和启动完整HumanEval数据集的大规模训练。

---

## 🎯 训练目标

### 当前训练（参考）
- **训练数据**: 每episode随机采样5个问题（共131个训练集）
- **训练进度**: Epoch 4/20
- **准确率**: 99.21%
- **每episode耗时**: ~2.79分钟

### 新的大规模训练
- **训练数据**: 每episode使用全部131个训练问题（无随机采样）
- **目标epochs**: 30
- **预计每episode耗时**: ~70分钟（26倍于当前）
- **预计每epoch耗时**: ~5.8小时（5个episodes）
- **预计总耗时**: ~174小时（~7.25天）

---

## 📦 准备的文件

### 1. deep_config_full_scale.yaml
**大规模训练配置文件**

关键配置：
```yaml
total_epochs: 30
episodes_per_epoch: 5
sample: 131  # *** 关键：使用全部131个训练问题 ***
experience_pool_size: 20000  # 增加经验池容量
output_dir: "./output/full_scale_training"
```

### 2. evaluate_full_dataset.py
**完整数据集评估脚本**

功能：
- 评估全部131个训练问题
- 评估全部33个测试问题
- 生成完整评估报告

使用方法：
```bash
python3 evaluate_full_dataset.py --config deep_config_full_scale.yaml
```

### 3. start_full_scale_training.sh
**训练启动脚本**

功能：
- 检查GPU可用性
- 验证CUDA配置
- 检查Qwen模型
- 启动后台训练
- 监控训练状态

使用方法：
```bash
./start_full_scale_training.sh
```

---

## 🚀 部署步骤

### 步骤1：连接到GPU服务器

```bash
ssh root@2.tcp.ngrok.io -p 17861
密码: wvJxpx0zRY1W
```

**注意**：当前此服务器端口不可访问，请确认正确的连接信息。

### 步骤2：验证GPU可用性

```bash
# 检查GPU
nvidia-smi

# 检查CUDA
python3 -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

**预期输出**：
- nvidia-smi显示GPU信息（至少16GB显存）
- CUDA available: True

### 步骤3：上传配置文件

将以下文件上传到服务器：
```
/root/aflow_verl_integration/integration/
├── deep_config_full_scale.yaml       # 大规模训练配置
├── evaluate_full_dataset.py           # 完整评估脚本
└── start_full_scale_training.sh       # 启动脚本
```

上传命令（从本地执行）：
```bash
scp -P 17861 \
    deep_config_full_scale.yaml \
    evaluate_full_dataset.py \
    start_full_scale_training.sh \
    root@2.tcp.ngrok.io:/root/aflow_verl_integration/integration/
```

### 步骤4：配置API密钥

在服务器上编辑配置文件，填入真实的OpenAI API密钥：

```bash
cd /root/aflow_verl_integration/integration/
vim deep_config_full_scale.yaml

# 修改以下字段：
# opt_llm_config:
#   key: "sk-YOUR_ACTUAL_API_KEY"  # 替换为真实API密钥
# exec_llm_config:
#   key: "sk-YOUR_ACTUAL_API_KEY"  # 替换为真实API密钥
```

### 步骤5：启动训练

```bash
cd /root/aflow_verl_integration/integration/
./start_full_scale_training.sh
```

脚本会：
1. 检查GPU和CUDA
2. 验证配置文件
3. 检查Qwen模型
4. 显示训练配置
5. 启动后台训练

### 步骤6：监控训练

#### 实时查看日志
```bash
tail -f full_scale_training.log
```

#### 查看最近的准确率
```bash
grep "Pass@" full_scale_training.log | tail -20
```

#### 查看训练进度
```bash
grep "Epoch" full_scale_training.log | tail -10
```

#### 检查训练进程
```bash
ps aux | grep deep_train_real_workflow.py
```

---

## 📊 训练配置详解

### 关键参数对比

| 参数 | 原配置 | 新配置 | 说明 |
|------|--------|--------|------|
| total_epochs | 20 | 30 | 增加训练轮数 |
| episodes_per_epoch | 10 | 5 | 减少episode数（每个更重） |
| sample | 5 | 131 | **关键**：使用全部训练集 |
| update_frequency | 5 | 3 | 更频繁更新策略 |
| experience_pool_size | 10000 | 20000 | 增加经验池 |
| save_frequency | 5 | 3 | 更频繁保存checkpoint |

### 时间估算

基于原配置的性能数据：
- 原配置每episode: ~2.79分钟（5个问题）
- 新配置每episode: ~70分钟（131个问题，26倍）
- 每epoch: 5 episodes × 70分钟 = ~350分钟 = ~5.8小时
- 总训练: 30 epochs × 5.8小时 = ~174小时 = ~7.25天

### 硬件要求

- **GPU**: 至少16GB显存（推荐24GB+）
- **CPU**: 多核处理器
- **内存**: 至少32GB RAM
- **存储**: 至少100GB可用空间（模型+日志+checkpoints）

---

## 🔬 训练监控指标

### 关键指标

1. **Pass@K准确率**
   - 每个round结束时输出
   - 监控训练集准确率趋势

2. **测试集评估**
   - 每个epoch结束时评估
   - 检查泛化能力

3. **Loss值**
   - Policy loss
   - Value loss
   - Entropy

4. **资源使用**
   ```bash
   # GPU使用率
   watch -n 1 nvidia-smi

   # 显存使用
   nvidia-smi --query-gpu=memory.used --format=csv
   ```

### 预期表现

基于之前训练的表现（sample=5时）：
- **训练集准确率**: 98-99%
- **测试集准确率**: 100%（10/33问题测试）

大规模训练预期：
- **训练集准确率**: 应保持在95%+（更难的完整集）
- **测试集准确率**: 目标100%（全部33个问题）
- **策略收敛**: 应在15-20 epochs后收敛

---

## 📁 输出文件结构

```
output/full_scale_training/
├── checkpoints/
│   ├── epoch_3/
│   ├── epoch_6/
│   ├── epoch_9/
│   └── ...
├── workflows_generated/
│   └── HumanEval/
│       ├── round_1_env0/
│       ├── round_1_env1/
│       └── ...
├── training_log.jsonl          # 结构化训练日志
└── evaluation_results.txt      # 评估结果

full_scale_training.log         # 完整训练日志（主日志）
```

---

## ✅ 完成训练后的评估

### 1. 停止训练（如果未自动完成）

```bash
# 查找训练进程
ps aux | grep deep_train_real_workflow.py

# 停止训练（使用实际PID）
kill <PID>
```

### 2. 运行完整数据集评估

```bash
python3 evaluate_full_dataset.py --config deep_config_full_scale.yaml
```

这将评估：
- ✅ 全部131个训练问题
- ✅ 全部33个测试问题
- ✅ 生成完整报告

### 3. 分析结果

查看评估报告：
```bash
cat full_evaluation_*.txt
```

### 4. 下载结果（可选）

从本地机器执行：
```bash
# 下载checkpoint
scp -P 17861 -r \
    root@2.tcp.ngrok.io:/root/aflow_verl_integration/integration/output/full_scale_training/checkpoints/epoch_30 \
    ./local_checkpoints/

# 下载日志
scp -P 17861 \
    root@2.tcp.ngrok.io:/root/aflow_verl_integration/integration/full_scale_training.log \
    ./

# 下载评估结果
scp -P 17861 \
    root@2.tcp.ngrok.io:/root/aflow_verl_integration/integration/full_evaluation_*.txt \
    ./
```

---

## ⚠️ 故障排查

### 问题1：CUDA不可用

**症状**：
```
RuntimeError: Found no NVIDIA driver on your system
CUDA available: False
```

**解决**：
- 确认服务器有GPU：`lspci | grep -i nvidia`
- 安装/更新NVIDIA驱动
- 检查CUDA安装：`nvcc --version`

### 问题2：显存不足

**症状**：
```
RuntimeError: CUDA out of memory
```

**解决**：
1. 减小batch_size（配置文件中）
2. 使用更小的model或启用gradient checkpointing
3. 减少env_num（并行环境数）

### 问题3：训练中断

**解决**：
训练支持断点续训，使用最新checkpoint继续：
```bash
python3 deep_train_real_workflow.py \
    --config deep_config_full_scale.yaml \
    --resume_from output/full_scale_training/checkpoints/latest
```

### 问题4：API密钥错误

**症状**：
```
OpenAI API error: Invalid API key
```

**解决**：
检查并更新配置文件中的API密钥：
```bash
vim deep_config_full_scale.yaml
# 更新 opt_llm_config.key 和 exec_llm_config.key
```

---

## 📞 当前状态

### 服务器连接
- **地址**: ssh root@2.tcp.ngrok.io -p 17861
- **密码**: wvJxpx0zRY1W
- **状态**: ⚠️ 当前端口不可访问，需要确认正确的连接信息

### 准备状态
✅ 配置文件已创建（deep_config_full_scale.yaml）
✅ 评估脚本已创建（evaluate_full_dataset.py）
✅ 启动脚本已创建（start_full_scale_training.sh）
⚠️ 等待服务器连接恢复
⚠️ 需要验证GPU可用性
⚠️ 需要填写真实API密钥

### 下一步
1. 确认正确的GPU服务器连接信息
2. 连接到服务器并验证GPU
3. 上传配置文件和脚本
4. 配置API密钥
5. 启动训练

---

## 📚 相关文档

- `deep_config_full_scale.yaml` - 大规模训练配置
- `evaluate_full_dataset.py` - 完整评估脚本
- `start_full_scale_training.sh` - 启动脚本
- `README.md` - 项目说明
- `训练深度分析报告.md` - 之前训练的分析报告

---

## 🎯 预期成果

完成大规模训练后，您将获得：

1. **完全训练的Qwen模型**
   - 在全部131个训练问题上训练
   - 30个epochs的充分学习
   - LoRA微调参数

2. **完整评估报告**
   - 131个训练问题的准确率
   - 33个测试问题的准确率
   - 整体164个问题的性能

3. **训练checkpoints**
   - 每3个epochs保存
   - 可用于继续训练或推理

4. **生成的workflows**
   - Qwen学习到的最优workflow策略
   - 可直接用于实际编程任务

---

**📝 文档生成时间**: 2025-10-15
**📍 文件位置**: `/Users/zhangmingda/Desktop/agent worflow/integration/`
**🎯 目标**: 在完整HumanEval数据集上进行大规模训练和评估
