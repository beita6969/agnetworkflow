# Quick Start Guide
# å¿«é€Ÿå¼€å§‹æŒ‡å—

ç«‹å³å¼€å§‹ä½¿ç”¨AFlow + verl-agentæ·±åº¦é›†æˆç³»ç»Ÿï¼

Get started with the AFlow + verl-agent deep integration system right away!

---

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹ 5-Minute Quick Start

### 1. å®‰è£…ä¾èµ– Install Dependencies

```bash
# åŸºç¡€ä¾èµ– Basic dependencies
pip install torch numpy pyyaml ray

# OpenAI API (å¯é€‰ï¼Œç”¨äºLLMè°ƒç”¨)
pip install openai

# å…¶ä»–å¯é€‰ä¾èµ– Optional dependencies
pip install tensorboard wandb
```

### 2. è®¾ç½®ç¯å¢ƒå˜é‡ Set Environment Variables

```bash
# OpenAI APIå¯†é’¥ï¼ˆå¦‚æœä½¿ç”¨OpenAIï¼‰
export OPENAI_API_KEY="sk-your-api-key-here"

# å¯é€‰: è‡ªå®šä¹‰APIç«¯ç‚¹
export OPENAI_BASE_URL="https://api.openai.com/v1"
```

### 3. ä¿®æ”¹é…ç½® Modify Configuration

ç¼–è¾‘ `integration/deep_config.yaml`:

```yaml
# æœ€å°ä¿®æ”¹ - åªéœ€ä¿®æ”¹è¿™å‡ é¡¹
environment:
  train_datasets:
    - "HumanEval"  # æˆ–æ‚¨çš„æ•°æ®é›†

  opt_llm_config:
    model: "gpt-4"  # æˆ–æ‚¨çš„æ¨¡å‹
    api_key: null   # ä½¿ç”¨ç¯å¢ƒå˜é‡

# å…¶ä»–ä¿æŒé»˜è®¤å³å¯
total_epochs: 5  # å¿«é€Ÿæµ‹è¯•ç”¨5è½®
```

### 4. å¯åŠ¨è®­ç»ƒ Start Training

```bash
cd integration
python deep_train.py --config deep_config.yaml
```

### 5. ç›‘æ§è¿›åº¦ Monitor Progress

```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f output/deep_integration/logs/training.log

# æŸ¥çœ‹ç»Ÿè®¡æ•°æ®
cat output/deep_integration/logs/training_stats.json
```

---

## ğŸ“‹ è¯¦ç»†æ­¥éª¤ Detailed Steps

### æ­¥éª¤1: ç¯å¢ƒå‡†å¤‡ Environment Setup

#### 1.1 æ£€æŸ¥Pythonç‰ˆæœ¬ Check Python Version

```bash
python --version
# éœ€è¦ Python 3.8+
```

#### 1.2 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰Create Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows
```

#### 1.3 å®‰è£…ä¾èµ– Install Dependencies

```bash
# æ–¹å¼1: ç›´æ¥å®‰è£… Direct installation
pip install torch numpy pyyaml ray openai

# æ–¹å¼2: ä½¿ç”¨requirements.txt (å¦‚æœæä¾›)
# pip install -r requirements.txt
```

#### 1.4 éªŒè¯å®‰è£… Verify Installation

```bash
python -c "import torch, numpy, yaml, ray; print('All dependencies installed!')"
```

### æ­¥éª¤2: é…ç½®ç³»ç»Ÿ Configure System

#### 2.1 æŸ¥çœ‹é…ç½®æ–‡ä»¶ View Configuration

```bash
cd integration
cat deep_config.yaml
```

#### 2.2 æœ€å°é…ç½®ä¿®æ”¹ Minimal Configuration Changes

åˆ›å»ºæ‚¨è‡ªå·±çš„é…ç½®æ–‡ä»¶ `my_config.yaml`:

```yaml
# my_config.yaml - æœ€å°é…ç½®ç¤ºä¾‹
device: "cuda"  # æˆ– "cpu"
output_dir: "./my_output"
total_epochs: 10

environment:
  train_datasets:
    - "HumanEval"

  env_num: 2  # å¹¶è¡Œç¯å¢ƒæ•°é‡
  group_n: 2  # GiGPOåˆ†ç»„æ•°é‡

  opt_llm_config:
    model: "gpt-4"
    temperature: 0.7
    max_tokens: 2000

rl:
  initial_weight: 0.5
  weight_schedule: "linear_increase"
```

#### 2.3 é«˜çº§é…ç½®ï¼ˆå¯é€‰ï¼‰Advanced Configuration (Optional)

```yaml
# è°ƒæ•´RLå‚æ•°
rl:
  gigpo:
    enable_similarity: true
    similarity_thresh: 0.95
    workflow_similarity_thresh: 0.8

# è°ƒæ•´å¹¶è¡Œæ€§
environment:
  env_num: 4
  group_n: 2

# å¯ç”¨å®éªŒè·Ÿè¸ª
experiment:
  use_wandb: true
  wandb_project: "my-aflow-project"
```

### æ­¥éª¤3: è¿è¡Œè®­ç»ƒ Run Training

#### 3.1 åŸºç¡€è®­ç»ƒ Basic Training

```bash
cd integration
python deep_train.py --config deep_config.yaml
```

#### 3.2 ä½¿ç”¨è‡ªå®šä¹‰é…ç½® Use Custom Configuration

```bash
python deep_train.py --config my_config.yaml
```

#### 3.3 è¦†ç›–é…ç½®å‚æ•° Override Configuration

```bash
python deep_train.py \
  --config deep_config.yaml \
  --output_dir ./custom_output \
  --device cuda
```

#### 3.4 è°ƒè¯•æ¨¡å¼ Debug Mode

åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨è°ƒè¯•:

```yaml
debug:
  enable_debug_mode: true
  debug_episodes: 5
  verbose_env: true
  verbose_rl: true
```

ç„¶åè¿è¡Œ:

```bash
python deep_train.py --config deep_config.yaml
```

### æ­¥éª¤4: ç›‘æ§è®­ç»ƒ Monitor Training

#### 4.1 å®æ—¶æ—¥å¿— Real-time Logs

```bash
# ç»ˆç«¯1: è¿è¡Œè®­ç»ƒ
python deep_train.py --config deep_config.yaml

# ç»ˆç«¯2: ç›‘æ§æ—¥å¿—
tail -f output/deep_integration/logs/training.log
```

#### 4.2 æŸ¥çœ‹ç»Ÿè®¡ View Statistics

```bash
# è®­ç»ƒç»Ÿè®¡
cat output/deep_integration/logs/training_stats.json

# è¯„ä¼°ç»“æœ
cat output/deep_integration/logs/eval_epoch_5.json
```

#### 4.3 å¯è§†åŒ–ï¼ˆPythonï¼‰Visualization (Python)

```python
import json
import matplotlib.pyplot as plt

# åŠ è½½ç»Ÿè®¡æ•°æ®
with open('output/deep_integration/logs/training_stats.json') as f:
    stats = json.load(f)

# ç»˜åˆ¶è®­ç»ƒæ›²çº¿
plt.figure(figsize=(10, 6))
plt.plot(stats['avg_scores'])
plt.xlabel('Epoch')
plt.ylabel('Average Score')
plt.title('Training Progress')
plt.grid(True)
plt.savefig('training_progress.png')
plt.show()
```

#### 4.4 TensorBoardï¼ˆå¯é€‰ï¼‰TensorBoard (Optional)

```bash
# å¯ç”¨TensorBoard (åœ¨é…ç½®ä¸­)
# logging:
#   use_tensorboard: true

# è¿è¡ŒTensorBoard
tensorboard --logdir output/tensorboard
```

### æ­¥éª¤5: æ£€æŸ¥ç»“æœ Check Results

#### 5.1 æŸ¥çœ‹è¾“å‡ºç›®å½• View Output Directory

```bash
tree output/deep_integration/

# ç»“æ„ Structure:
# output/deep_integration/
# â”œâ”€â”€ checkpoints/
# â”‚   â”œâ”€â”€ best.pt
# â”‚   â”œâ”€â”€ best_pool.pkl
# â”‚   â””â”€â”€ epoch_5.pt
# â”œâ”€â”€ logs/
# â”‚   â”œâ”€â”€ training.log
# â”‚   â”œâ”€â”€ training_stats.json
# â”‚   â””â”€â”€ eval_epoch_5.json
# â””â”€â”€ optimized_workflows/
#     â”œâ”€â”€ train/
#     â””â”€â”€ test/
```

#### 5.2 åŠ è½½æœ€ä½³æ£€æŸ¥ç‚¹ Load Best Checkpoint

```python
import torch

# åŠ è½½æ£€æŸ¥ç‚¹
checkpoint = torch.load('output/deep_integration/checkpoints/best.pt')

print(f"Best epoch: {checkpoint['epoch']}")
print(f"Best score: {checkpoint['stats']['best_score']}")
```

#### 5.3 æŸ¥çœ‹ä¼˜åŒ–çš„å·¥ä½œæµ View Optimized Workflows

```bash
# æŸ¥çœ‹æŸä¸ªæ•°æ®é›†çš„ä¼˜åŒ–ç»“æœ
cat output/deep_integration/optimized_workflows/train/HumanEval/workflows/round_10/graph.py
```

---

## ğŸ”§ å¸¸è§é—®é¢˜è§£å†³ Troubleshooting

### é—®é¢˜1: ImportError

**é”™è¯¯ Error:**
```
ImportError: No module named 'scripts.optimizer_rl'
```

**è§£å†³ Solution:**
```bash
# ç¡®ä¿è·¯å¾„æ­£ç¡®
export PYTHONPATH="${PYTHONPATH}:$(pwd)/AFlow"
export PYTHONPATH="${PYTHONPATH}:$(pwd)/verl-agent"
export PYTHONPATH="${PYTHONPATH}:$(pwd)/integration"

# æˆ–åœ¨Pythonä¸­æ·»åŠ 
import sys
sys.path.insert(0, '/path/to/AFlow')
sys.path.insert(0, '/path/to/verl-agent')
sys.path.insert(0, '/path/to/integration')
```

### é—®é¢˜2: Rayåˆå§‹åŒ–å¤±è´¥

**é”™è¯¯ Error:**
```
RuntimeError: Ray has not been started yet
```

**è§£å†³ Solution:**
```python
# åœ¨ä»£ç ä¸­
import ray
if not ray.is_initialized():
    ray.init()
```

### é—®é¢˜3: OpenAI APIé”™è¯¯

**é”™è¯¯ Error:**
```
openai.error.AuthenticationError: Invalid API key
```

**è§£å†³ Solution:**
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $OPENAI_API_KEY

# é‡æ–°è®¾ç½®
export OPENAI_API_KEY="sk-your-correct-api-key"

# æˆ–åœ¨é…ç½®æ–‡ä»¶ä¸­ç›´æ¥æŒ‡å®š
# opt_llm_config:
#   api_key: "sk-your-api-key"
```

### é—®é¢˜4: CUDAå†…å­˜ä¸è¶³

**é”™è¯¯ Error:**
```
RuntimeError: CUDA out of memory
```

**è§£å†³ Solution:**
```yaml
# åœ¨é…ç½®ä¸­å‡å°‘å¹¶è¡Œæ•°
environment:
  env_num: 2  # ä»4é™åˆ°2
  group_n: 1  # ä»2é™åˆ°1

# æˆ–ä½¿ç”¨CPU
device: "cpu"
```

### é—®é¢˜5: è®­ç»ƒå¾ˆæ…¢

**è§£å†³ Solution:**

1. å‡å°‘ç¯å¢ƒæ•°é‡:
```yaml
environment:
  env_num: 2
  max_rounds: 10  # ä»20é™åˆ°10
```

2. ä½¿ç”¨æ›´å¿«çš„LLM:
```yaml
opt_llm_config:
  model: "gpt-3.5-turbo"  # ä»£æ›¿gpt-4
```

3. å‡å°‘éªŒè¯è½®æ¬¡:
```yaml
environment:
  validation_rounds: 3  # ä»5é™åˆ°3
```

---

## ğŸ“Š éªŒè¯å®‰è£… Verify Installation

è¿è¡Œä»¥ä¸‹è„šæœ¬éªŒè¯æ‰€æœ‰ç»„ä»¶æ­£å¸¸:

```python
# verify_installation.py
import sys
import os

print("Verifying installation...")

# 1. Check imports
try:
    from integration.unified_state import WorkflowState, StateManager
    print("âœ“ unified_state imported")
except ImportError as e:
    print(f"âœ— unified_state import failed: {e}")

try:
    from AFlow.scripts.shared_experience import SharedExperiencePool
    print("âœ“ shared_experience imported")
except ImportError as e:
    print(f"âœ— shared_experience import failed: {e}")

try:
    from AFlow.scripts.optimizer_rl import RLEnhancedOptimizer
    print("âœ“ optimizer_rl imported")
except ImportError as e:
    print(f"âœ— optimizer_rl import failed: {e}")

try:
    from verl_agent.gigpo.workflow_gigpo import compute_workflow_gigpo_advantage
    print("âœ“ workflow_gigpo imported")
except ImportError as e:
    print(f"âœ— workflow_gigpo import failed: {e}")

# 2. Check Ray
try:
    import ray
    if not ray.is_initialized():
        ray.init()
    print("âœ“ Ray initialized")
except Exception as e:
    print(f"âœ— Ray initialization failed: {e}")

# 3. Check configuration
try:
    import yaml
    with open('integration/deep_config.yaml') as f:
        config = yaml.safe_load(f)
    print("âœ“ Configuration loaded")
except Exception as e:
    print(f"âœ— Configuration loading failed: {e}")

print("\nInstallation verification complete!")
```

è¿è¡ŒéªŒè¯:
```bash
python verify_installation.py
```

---

## ğŸ¯ ç¤ºä¾‹å·¥ä½œæµ Example Workflow

### å®Œæ•´ç¤ºä¾‹: è®­ç»ƒHumanEval

```bash
# 1. å‡†å¤‡ç¯å¢ƒ
cd "/Users/zhangmingda/Desktop/agent worflow"
export OPENAI_API_KEY="your-key-here"

# 2. åˆ›å»ºè‡ªå®šä¹‰é…ç½®
cat > integration/humaneval_config.yaml << EOF
device: "cuda"
output_dir: "./output/humaneval_experiment"
total_epochs: 10
episodes_per_epoch: 20

environment:
  train_datasets:
    - "HumanEval"
  test_datasets:
    - "HumanEval"

  env_num: 2
  group_n: 2
  max_rounds: 15

  opt_llm_config:
    model: "gpt-4"
    temperature: 0.7

rl:
  initial_weight: 0.4
  weight_schedule: "linear_increase"
EOF

# 3. å¯åŠ¨è®­ç»ƒ
cd integration
python deep_train.py --config humaneval_config.yaml 2>&1 | tee training.log

# 4. ç›‘æ§ï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
watch -n 5 'tail -20 output/humaneval_experiment/logs/training.log'

# 5. è®­ç»ƒå®ŒæˆåæŸ¥çœ‹ç»“æœ
cat output/humaneval_experiment/logs/training_stats.json | jq '.best_score'

# 6. å¯è§†åŒ–
python << EOF
import json
import matplotlib.pyplot as plt

with open('output/humaneval_experiment/logs/training_stats.json') as f:
    stats = json.load(f)

plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.plot(stats['avg_scores'])
plt.title('Average Score')
plt.xlabel('Epoch')
plt.ylabel('Score')

plt.subplot(1, 3, 2)
plt.plot(stats['experience_pool_size'])
plt.title('Experience Pool Size')
plt.xlabel('Epoch')

plt.subplot(1, 3, 3)
plt.plot(stats['state_manager_size'])
plt.title('State Manager Size')
plt.xlabel('Epoch')

plt.tight_layout()
plt.savefig('training_analysis.png')
print("Saved to training_analysis.png")
EOF
```

---

## ğŸ“š æ›´å¤šèµ„æº More Resources

### æ–‡æ¡£ Documentation

- **å®Œæ•´æ–‡æ¡£**: `integration/README.md`
- **å®ç°æ€»ç»“**: `IMPLEMENTATION_SUMMARY.md`
- **äº¤ä»˜æ¸…å•**: `DELIVERABLES_CHECKLIST.md`

### é…ç½®ç¤ºä¾‹ Configuration Examples

- **åŸºç¡€é…ç½®**: `integration/deep_config.yaml`
- **æœ€å°é…ç½®**: è§ä¸Šæ–‡ "Minimal Configuration Changes"

### ä»£ç ç¤ºä¾‹ Code Examples

```python
# è‡ªå®šä¹‰RLç­–ç•¥
class MyPolicy:
    def get_q_value(self, state_repr: str) -> float:
        # æ‚¨çš„Qå€¼ä¼°è®¡é€»è¾‘
        return 0.5

    def suggest_action(self, state_repr: str) -> str:
        # æ‚¨çš„åŠ¨ä½œå»ºè®®é€»è¾‘
        return "Optimize the workflow structure"

    def get_action(self, obs: str) -> str:
        # æ‚¨çš„åŠ¨ä½œç”Ÿæˆé€»è¾‘
        return "Add ScEnsemble operator"

# ä½¿ç”¨è‡ªå®šä¹‰ç­–ç•¥
from integration.deep_train import DeepIntegratedTrainer

trainer = DeepIntegratedTrainer(config)
trainer.set_rl_policy(MyPolicy())
trainer.train()
```

---

## ğŸ†˜ è·å–å¸®åŠ© Get Help

### æ£€æŸ¥æ—¥å¿— Check Logs

```bash
# è¯¦ç»†é”™è¯¯ä¿¡æ¯
cat output/deep_integration/logs/training.log | grep ERROR

# è­¦å‘Šä¿¡æ¯
cat output/deep_integration/logs/training.log | grep WARNING
```

### å¯ç”¨è¯¦ç»†æ—¥å¿— Enable Verbose Logging

```yaml
# åœ¨é…ç½®ä¸­
logging:
  level: "DEBUG"

debug:
  verbose_env: true
  verbose_rl: true
  verbose_gigpo: true
```

### å¸¸è§é”™è¯¯æ¨¡å¼ Common Error Patterns

1. **è·¯å¾„é—®é¢˜**: ç¡®ä¿æ‰€æœ‰`sys.path`è®¾ç½®æ­£ç¡®
2. **ä¾èµ–é—®é¢˜**: è¿è¡Œ`pip list`æ£€æŸ¥å·²å®‰è£…åŒ…
3. **é…ç½®é—®é¢˜**: éªŒè¯YAMLè¯­æ³•æ­£ç¡®
4. **APIé—®é¢˜**: æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥
5. **èµ„æºé—®é¢˜**: ç›‘æ§CPU/GPU/å†…å­˜ä½¿ç”¨

---

## âœ… æ£€æŸ¥æ¸…å• Checklist

å¼€å§‹è®­ç»ƒå‰ï¼Œç¡®ä¿:

- [ ] Python 3.8+ å·²å®‰è£…
- [ ] æ‰€æœ‰ä¾èµ–å·²å®‰è£… (`pip install ...`)
- [ ] ç¯å¢ƒå˜é‡å·²è®¾ç½® (OPENAI_API_KEY)
- [ ] é…ç½®æ–‡ä»¶å·²å‡†å¤‡
- [ ] è¾“å‡ºç›®å½•æœ‰å†™æƒé™
- [ ] (å¯é€‰) GPUå¯ç”¨ä¸”CUDAé…ç½®æ­£ç¡®
- [ ] (å¯é€‰) Rayé›†ç¾¤å¯ç”¨

---

## ğŸ‰ å¼€å§‹è®­ç»ƒï¼Start Training!

ä¸€åˆ‡å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹æ‚¨çš„æ·±åº¦é›†æˆè®­ç»ƒä¹‹æ—…ï¼

Everything is ready, start your deep integration training journey!

```bash
cd integration
python deep_train.py --config deep_config.yaml
```

ç¥è®­ç»ƒé¡ºåˆ©ï¼Good luck with your training!

---

**å¿«é€Ÿå‚è€ƒ Quick Reference:**
- é…ç½®æ–‡ä»¶: `integration/deep_config.yaml`
- è®­ç»ƒè„šæœ¬: `integration/deep_train.py`
- å®Œæ•´æ–‡æ¡£: `integration/README.md`
- å®ç°æ€»ç»“: `IMPLEMENTATION_SUMMARY.md`
